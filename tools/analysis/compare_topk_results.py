#!/usr/bin/env python3
"""
å¯¹æ¯”åˆ†æï¼šTop-K=5 vs Top-K=3 çš„æ•ˆæœ
"""
import json
from collections import Counter

def analyze_results(filepath, label):
    """åˆ†æå•ä¸ªç»“æœæ–‡ä»¶"""
    print(f"\n{'='*80}")
    print(f"{label}")
    print(f"{'='*80}")
    
    try:
        with open(filepath, 'r') as f:
            results = json.load(f)
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        return None
    
    print(f"\nå…± {len(results)} ä¸ªé—®é¢˜")
    
    # 1. é¢„æµ‹ç­”æ¡ˆåˆ†å¸ƒ
    pred_answers = [r['pred_answer'] for r in results]
    answer_dist = Counter(pred_answers)
    
    print(f"\nğŸ“Š é¢„æµ‹ç­”æ¡ˆåˆ†å¸ƒ:")
    for answer, count in answer_dist.most_common():
        print(f"   {answer}: {count} ({count/len(results)*100:.1f}%)")
    
    # 2. æ£€ç´¢åˆ†æ•°ç»Ÿè®¡
    all_scores = []
    for r in results:
        if 'sorted_passage_scores' in r:
            all_scores.extend(r['sorted_passage_scores'])
    
    if all_scores:
        print(f"\nğŸ¯ æ£€ç´¢åˆ†æ•°ç»Ÿè®¡:")
        print(f"   å¹³å‡åˆ†: {sum(all_scores)/len(all_scores):.6f}")
        print(f"   æœ€é«˜åˆ†: {max(all_scores):.6f}")
        print(f"   æœ€ä½åˆ†: {min(all_scores):.6f}")
        print(f"   ä¸­ä½æ•°: {sorted(all_scores)[len(all_scores)//2]:.6f}")
    
    # 3. æ£€æŸ¥ç¬¬1ä¸ªé—®é¢˜çš„æ£€ç´¢è´¨é‡
    if results:
        first = results[0]
        print(f"\nğŸ” ç¬¬1ä¸ªé—®é¢˜æ£€ç´¢ç¤ºä¾‹:")
        print(f"   é—®é¢˜: {first['question'][:60]}...")
        print(f"   æ­£ç¡®ç­”æ¡ˆ: {first['answer']}")
        print(f"   é¢„æµ‹ç­”æ¡ˆ: {first['pred_answer']}")
        if 'sorted_passage_scores' in first:
            print(f"   æ£€ç´¢åˆ†æ•°: {first['sorted_passage_scores']}")
        
        # æ£€æŸ¥æ£€ç´¢åˆ°çš„æ–‡æ¡£æ˜¯å¦ç›¸å…³
        if 'sorted_passage' in first and first['sorted_passage']:
            first_doc = first['sorted_passage'][0]
            question_lower = first['question'].lower()
            doc_lower = first_doc[:200].lower()
            
            # æå–é—®é¢˜ä¸­çš„å…³é”®åŒ»å­¦æœ¯è¯­
            keywords = []
            for word in question_lower.split():
                if len(word) > 5 and word.isalpha():
                    keywords.append(word)
            
            relevance_score = sum(1 for kw in keywords if kw in doc_lower)
            print(f"   ç›¸å…³åº¦è¯„ä¼°: {relevance_score}/{len(keywords)} å…³é”®è¯åŒ¹é…")
            print(f"   ç¬¬1ä¸ªæ–‡æ¡£: {first_doc[:150]}...")
    
    return {
        'total': len(results),
        'pred_dist': answer_dist,
        'avg_score': sum(all_scores)/len(all_scores) if all_scores else 0,
        'max_score': max(all_scores) if all_scores else 0,
    }

def main():
    print("="*80)
    print("PubMedQA Results Comparison: Top-K=5 vs Top-K=3")
    print("="*80)
    
    # åˆ†æä¹‹å‰çš„ç»“æœ (top-k=5, 500ä¸ªé—®é¢˜)
    old_stats = analyze_results(
        'results_pubmed_pubmedqa_pubmedqa.json',
        'ğŸ“‹ ä¹‹å‰çš„æµ‹è¯• (Top-K=5, 500ä¸ªé—®é¢˜)'
    )
    
    # åˆ†ææ–°çš„ç»“æœ (top-k=3, 50ä¸ªé—®é¢˜)
    new_stats = analyze_results(
        'results_pubmed_pubmedqa_pubmedqa.json',
        'ğŸ“‹ ä¿®å¤åçš„æµ‹è¯• (Top-K=3, 50ä¸ªé—®é¢˜)'
    )
    
    # å¯¹æ¯”åˆ†æ
    if old_stats and new_stats:
        print(f"\n{'='*80}")
        print("ğŸ“Š å¯¹æ¯”åˆ†æ")
        print(f"{'='*80}")
        
        print(f"\næ£€ç´¢è´¨é‡å¯¹æ¯”:")
        print(f"   ä¹‹å‰å¹³å‡åˆ†: {old_stats['avg_score']:.6f}")
        print(f"   ä¿®å¤åå¹³å‡åˆ†: {new_stats['avg_score']:.6f}")
        print(f"   å˜åŒ–: {(new_stats['avg_score']/old_stats['avg_score']-1)*100:+.1f}%")
        
        print(f"\né¢„æµ‹å¤šæ ·æ€§å¯¹æ¯”:")
        print(f"   ä¹‹å‰: {len(old_stats['pred_dist'])} ç§ç­”æ¡ˆ")
        print(f"   ä¿®å¤å: {len(new_stats['pred_dist'])} ç§ç­”æ¡ˆ")
        
        # æœŸæœ›æ”¹è¿›
        print(f"\næœŸæœ›æ”¹è¿›:")
        print(f"   âœ… Top-Kä»5â†’3åº”è¯¥å‡å°‘å™ªå£°")
        print(f"   âœ… æ£€ç´¢åˆ†æ•°åº”è¯¥æœ‰æ˜¾è‘—æå‡ï¼ˆå¦‚æœcorpusæ­£ç¡®ï¼‰")
        print(f"   âœ… é¢„æµ‹ç­”æ¡ˆåº”è¯¥æ›´å¤šæ ·åŒ–ï¼ˆä¸å…¨æ˜¯Maybeï¼‰")

if __name__ == '__main__':
    main()
