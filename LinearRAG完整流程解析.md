# LinearRAG + Hypergraph å®Œæ•´æµç¨‹è§£æ

## ğŸ“‹ ç›®å½•
1. [ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ](#ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ)
2. [æ ¸å¿ƒæ•°æ®ç»“æ„](#æ ¸å¿ƒæ•°æ®ç»“æ„)
3. [ç´¢å¼•æ„å»ºæµç¨‹](#ç´¢å¼•æ„å»ºæµç¨‹)
4. [æ£€ç´¢é—®ç­”æµç¨‹](#æ£€ç´¢é—®ç­”æµç¨‹)
5. [å…·ä½“ç¤ºä¾‹è¯¦è§£](#å…·ä½“ç¤ºä¾‹è¯¦è§£)

---

## ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

LinearRAGæ˜¯ä¸€ä¸ªåŸºäº**å›¾ç»“æ„**å’Œ**è¶…å›¾(Hypergraph)**çš„æ··åˆæ£€ç´¢ç³»ç»Ÿ,ç”¨äºåŒ»å­¦æ–‡çŒ®é—®ç­”ã€‚

### æ ¸å¿ƒæ€æƒ³
```
ä¼ ç»ŸRAG: Query â†’ Dense Retrieval â†’ Top-Kæ–‡æ¡£ â†’ LLMç”Ÿæˆ
LinearRAG: Query â†’ å®ä½“è¯†åˆ« â†’ å›¾éå†(PPR) â†’ è¶…å›¾å¢å¼º â†’ Top-Kæ–‡æ¡£ â†’ LLMç”Ÿæˆ
```

### å…³é”®åˆ›æ–°ç‚¹
1. **å®ä½“ä¸­å¿ƒçš„å›¾ç»“æ„**: å°†æ–‡æ¡£ã€å®ä½“ã€å¥å­å»ºæ¨¡ä¸ºå›¾èŠ‚ç‚¹
2. **è¶…å›¾å¢å¼º**: æ•æ‰å¤šå®ä½“å…±ç°å…³ç³»(nå…ƒå…³ç³»)
3. **æ··åˆæ£€ç´¢**: ç»“åˆå¯†é›†æ£€ç´¢(DPR)å’Œå›¾éå†(PPR)
4. **åŒ»å­¦é¢†åŸŸä¼˜åŒ–**: ä¸“ç”¨NERã€åŒ»å­¦å…³ç³»æ¨¡å¼è¯†åˆ«

---

## æ ¸å¿ƒæ•°æ®ç»“æ„

### 1. åŸºç¡€å›¾ (LinearRAG Graph)
```
å›¾G = (V, E)
V = V_passage âˆª V_entity âˆª V_sentence
  - V_passage: æ–‡æ¡£èŠ‚ç‚¹(passage chunks)
  - V_entity: å®ä½“èŠ‚ç‚¹(åŒ»å­¦å®ä½“)
  - V_sentence: å¥å­èŠ‚ç‚¹(åŒ…å«å®ä½“çš„å¥å­)

E = E_passage-entity âˆª E_entity-sentence âˆª E_passage-passage
  - E_passage-entity: æ–‡æ¡£åŒ…å«å®ä½“
  - E_entity-sentence: å¥å­åŒ…å«å®ä½“
  - E_passage-passage: ç›¸é‚»æ–‡æ¡£(é¡ºåºå…³ç³»)
```

**èŠ‚ç‚¹å±æ€§**:
- `name`: hash_id (å”¯ä¸€æ ‡è¯†)
- `content`: æ–‡æœ¬å†…å®¹
- `type`: èŠ‚ç‚¹ç±»å‹ (passage/entity/sentence)

**è¾¹æƒé‡**:
- passageâ†’entity: TF(å®ä½“åœ¨æ–‡æ¡£ä¸­çš„é¢‘ç‡å½’ä¸€åŒ–)
- entityâ†’sentence: å…±ç°å…³ç³»
- passageâ†’passage: 1.0(ç›¸é‚»æ–‡æ¡£)

### 2. è¶…å›¾ (Hypergraph)
```
è¶…å›¾ G_H = (V_H, E_H)
V_H = å®ä½“é›†åˆ
E_H = è¶…è¾¹é›†åˆ(hyperedges)

è¶…è¾¹ e_H = {v1, v2, ..., vn} âŠ† V_H
  - æ¥æº: åŒä¸€å¥å­ä¸­å…±ç°çš„nä¸ªå®ä½“
  - æè¿°: è¯¥å¥å­çš„åŸæ–‡æœ¬
  - ç½®ä¿¡åº¦åˆ†æ•°: score âˆˆ [0, 1.5]
```

**è¶…è¾¹æ•°æ®ç»“æ„**:
```python
@dataclass
class Hyperedge:
    text: str                    # åŸå¥å­æ–‡æœ¬ (è¶…è¾¹çš„è‡ªç„¶è¯­è¨€æè¿°)
    entities: List[str]          # å‚ä¸çš„å®ä½“åˆ—è¡¨ (â‰¥2ä¸ª)
    score: float                 # ç½®ä¿¡åº¦ (åŸºäºå®ä½“æ•°é‡å’ŒåŒ»å­¦æ¨¡å¼)
    hash_id: str                 # å”¯ä¸€æ ‡è¯†
    entity_types: Dict[str,str]  # å®ä½“ç±»å‹æ˜ å°„
```

**å­˜å‚¨ç»“æ„(äºŒéƒ¨å›¾è¡¨ç¤º)**:
```
è¶…å›¾å­˜å‚¨ä¸ºäºŒéƒ¨å›¾ G_B = (V_B, E_B)
V_B = V_entity âˆª V_hyperedge
E_B = {(v, e_H) | v âˆˆ e_H}

è¿™æ ·å¯ä»¥é«˜æ•ˆæŸ¥è¯¢:
- ç»™å®šå®ä½“ â†’ è·å–åŒ…å«å®ƒçš„æ‰€æœ‰è¶…è¾¹
- ç»™å®šè¶…è¾¹ â†’ è·å–å…¶åŒ…å«çš„æ‰€æœ‰å®ä½“
```

### 3. æ˜ å°„å…³ç³»è¡¨
```python
# Passage â†” Hyperedge
passage_to_hyperedge_ids: Dict[str, List[str]]
  # passage_hash_id â†’ [hyperedge_hash_ids]

# Entity â†” Hyperedge (äºŒéƒ¨å›¾é‚»æ¥è¡¨)
entity_to_hyperedges: Dict[str, Set[str]]
hyperedge_to_entities: Dict[str, Set[str]]

# Entity â†” Sentence
entity_hash_id_to_sentence_hash_ids: Dict[str, List[str]]
sentence_hash_id_to_entity_hash_ids: Dict[str, List[str]]

# Hash ID â†” Text
passage_embedding_store.hash_id_to_text: Dict[str, str]
entity_embedding_store.hash_id_to_text: Dict[str, str]
hyperedge_hash_to_text: Dict[str, str]
```

---

## ç´¢å¼•æ„å»ºæµç¨‹

### å®Œæ•´æµç¨‹å›¾
```
è¾“å…¥: passages (20000ç¯‡PubMedæ–‡çŒ®)
  â†“
[Step 1] æ’å…¥passages â†’ EmbeddingStore
  - ç”Ÿæˆembeddings (SentenceTransformer)
  - è®¡ç®—hash_id: md5(text)[:16]
  â†“
[Step 2-3] åŠ è½½å·²æœ‰NERç»“æœ (å¢é‡ç´¢å¼•)
  - è¯»å– ner_results.json
  - è¯†åˆ«æ–°æ–‡æ¡£: new_hash_ids = current - existing
  â†“
[Step 4] æ‰¹é‡NERå¤„ç† (æ··åˆç­–ç•¥)
  - BC5CDR NER (spaCy): CHEMICAL, DISEASE
  - HuggingFace NER: æ›´å¤šåŒ»å­¦å®ä½“ç±»å‹
  - æå–: passage_hash_id_to_entities, sentence_to_entities
  â†“
[Step 5] ä¿å­˜NERç»“æœ â†’ ner_results.json
  â†“
[Step 6] æ„å»ºåŸºç¡€å›¾èŠ‚ç‚¹å’Œè¾¹
  - æå–: entity_nodes, sentence_nodes
  - æ„å»ºæ˜ å°„: entity_to_sentence, sentence_to_entity
  â†“
[Step 6.5] ğŸ”¥ æ„å»ºè¶…å›¾ (HyperLinearRAGæ ¸å¿ƒ)
  â”‚
  â”œâ”€ 6.5.1 ä»å¥å­å…±ç°æ„å»ºè¶…è¾¹
  â”‚   for sentence, entities in sentence_to_entities.items():
  â”‚       if len(entities) >= 2:  # è‡³å°‘2ä¸ªå®ä½“
  â”‚           hyperedge = Hyperedge(
  â”‚               text=sentence,
  â”‚               entities=list(entities),
  â”‚               score=len(entities) / max_entity_count
  â”‚           )
  â”‚
  â”œâ”€ 6.5.2 åŒ»å­¦æ¨¡å¼å¢å¼ºåˆ†æ•°
  â”‚   for hyperedge in hyperedges:
  â”‚       entity_types = get_entity_types(hyperedge.entities)
  â”‚       # æ£€æµ‹åŒ»å­¦å…³ç³»æ¨¡å¼
  â”‚       if {DISEASE, CHEMICAL} âŠ† entity_types:
  â”‚           score *= 1.3  # ç–¾ç—…-è¯ç‰©å…³ç³»
  â”‚       if {SYMPTOM, DISEASE} âŠ† entity_types:
  â”‚           score *= 1.2  # ç—‡çŠ¶-ç–¾ç—…å…³ç³»
  â”‚       # ... æ›´å¤šæ¨¡å¼
  â”‚
  â”œâ”€ 6.5.3 å­˜å‚¨åˆ°HypergraphStore
  â”‚   - æ„å»ºäºŒéƒ¨å›¾: entity â†” hyperedge
  â”‚   - ä¿å­˜: hyperedges.pkl, metadata.json
  â”‚
  â””â”€ 6.5.4 æ„å»ºpassage-hyperedgeæ˜ å°„
      for passage_hash_id, passage_text in passages:
          for hyperedge in hyperedges:
              if hyperedge.text in passage_text:
                  passage_to_hyperedge_ids[passage_hash_id].append(hyperedge.hash_id)
  â†“
[Step 7] æ„å»ºembeddings
  - entity_embeddings: (n_entities, 768)
  - sentence_embeddings: (n_sentences, 768)
  - passage_embeddings: (n_passages, 768)
  â†“
[Step 8] æ„å»ºigraphå›¾
  - æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹: passages, entities, sentences
  - æ·»åŠ è¾¹å’Œæƒé‡
  - ä¿å­˜: LinearRAG.graphml
  â†“
[Step 9] ğŸ”¥ åŠ è½½è¶…è¾¹embeddings
  - hyperedge_embeddings: (n_hyperedges, 768)
  - ç”¨äºåç»­æ£€ç´¢æ—¶çš„è¯­ä¹‰åŒ¹é…
  â†“
è¾“å‡º: ç´¢å¼•å®Œæˆ
  - å›¾ç»“æ„: graph (igraph.Graph)
  - è¶…å›¾: hypergraph_store
  - Embeddings: passage/entity/sentence/hyperedge
```

### å…³é”®ä»£ç è§£æ

#### Step 6.5: è¶…å›¾æ„å»º
```python
def _build_hypergraph(self, sentence_to_entities, hash_id_to_passage):
    """ä»å¥å­-å®ä½“å…±ç°æ„å»ºè¶…å›¾"""
    
    # 1. ä»å…±ç°æ„å»ºè¶…è¾¹
    hyperedges = self.hyperedge_builder.build_from_ner_results(
        sentence_to_entities  # {"å¥å­": {"å®ä½“1", "å®ä½“2", ...}}
    )
    # ç»“æœ: [Hyperedge(text="å¥å­", entities=["å®ä½“1",...], score=0.8), ...]
    
    # 2. åŒ»å­¦æ¨¡å¼å¢å¼º
    hyperedges = self.hyperedge_enhancer.enhance_hyperedges(hyperedges)
    # æ£€æµ‹åŒ»å­¦å…³ç³»æ¨¡å¼,æå‡ç›¸å…³è¶…è¾¹çš„score
    
    # 3. å­˜å‚¨åˆ°HypergraphStore (äºŒéƒ¨å›¾)
    self.hypergraph_store.add_hyperedges(hyperedges)
    
    # 4. æ„å»ºpassageâ†’hyperedgeæ˜ å°„
    passage_to_hyperedge_ids = {}
    for passage_hash_id, passage_text in hash_id_to_passage.items():
        for he in hyperedges:
            if he.text in passage_text:  # å¥å­åŒ…å«åœ¨passageä¸­
                passage_to_hyperedge_ids[passage_hash_id].append(he.hash_id)
    
    # 5. ä¿å­˜
    self.hypergraph_store.save()
    self.passage_to_hyperedge_ids = passage_to_hyperedge_ids
```

---

## æ£€ç´¢é—®ç­”æµç¨‹

### å®Œæ•´æµç¨‹å›¾
```
è¾“å…¥: question (ä¾‹: "What is the first-line treatment for type 2 diabetes?")
  â†“
[Phase 1] Queryå¤„ç†
  â”œâ”€ 1.1 NERæå–é—®é¢˜ä¸­çš„å®ä½“
  â”‚   question_entities = spacy_ner.question_ner(question)
  â”‚   # ä¾‹: ["type 2 diabetes", "treatment"]
  â”‚
  â”œâ”€ 1.2 å®ä½“åŒ¹é… (è¯­ä¹‰ç›¸ä¼¼åº¦)
  â”‚   question_entity_embeddings = encode(question_entities)
  â”‚   similarities = dot(entity_embeddings, question_entity_embeddings)
  â”‚   seed_entities = top_match_per_question_entity(similarities)
  â”‚   # ä¾‹: [("diabetes mellitus type 2", 0.95), ("drug therapy", 0.88)]
  â”‚
  â””â”€ 1.3 Question embedding
      question_embedding = encode(question)
  â†“
[Phase 2] ğŸ”¥ æ··åˆæ£€ç´¢ (HyperLinearRAG)
  â”‚
  â”œâ”€ 2.1 è¶…å›¾æ£€ç´¢ (hypergraph_retrieve)
  â”‚   â”‚
  â”‚   â”œâ”€ 2.1.1 è¶…è¾¹è¯­ä¹‰åŒ¹é…
  â”‚   â”‚   hyperedge_scores = dot(hyperedge_embeddings, question_embedding)
  â”‚   â”‚   # æ¯ä¸ªè¶…è¾¹çš„embeddingæ˜¯å…¶å¥å­çš„embedding
  â”‚   â”‚
  â”‚   â”œâ”€ 2.1.2 åº”ç”¨è¶…è¾¹ç½®ä¿¡åº¦
  â”‚   â”‚   for he_id, score in enumerate(hyperedge_scores):
  â”‚   â”‚       conf_score = hypergraph_store.get_hyperedge_score(he_id)
  â”‚   â”‚       hyperedge_scores[he_id] *= conf_score
  â”‚   â”‚
  â”‚   â”œâ”€ 2.1.3 Top-Kè¶…è¾¹ç­›é€‰
  â”‚   â”‚   top_hyperedges = argsort(hyperedge_scores)[:30]
  â”‚   â”‚   top_hyperedges = [he for he in top_hyperedges if score > 0.3]
  â”‚   â”‚
  â”‚   â””â”€ 2.1.4 åŒå‘å®ä½“æ‰©å±•
  â”‚       expanded_entities = set()
  â”‚       # æ–¹å‘1: ä»è¶…è¾¹æ‰©å±•
  â”‚       for he_id in top_hyperedges:
  â”‚           entities = hypergraph_store.get_entities_by_hyperedge(he_id)
  â”‚           expanded_entities.update(entities)
  â”‚       
  â”‚       # æ–¹å‘2: ä»ç§å­å®ä½“æ‰©å±•
  â”‚       for entity_id in seed_entity_hash_ids:
  â”‚           related_hyperedges = hypergraph_store.get_hyperedges_by_entity(entity_id)
  â”‚           for he_id in related_hyperedges:
  â”‚               entities = hypergraph_store.get_entities_by_hyperedge(he_id)
  â”‚               expanded_entities.update(entities)
  â”‚       
  â”‚       # ç»“æœ: expanded_entities (æ‰©å±•çš„å®ä½“é›†åˆ,ç”¨äºåç»­å¢å¼º)
  â”‚
  â”œâ”€ 2.2 LinearRAGå›¾æ£€ç´¢ (graph_search_with_seed_entities)
  â”‚   â”‚
  â”‚   â”œâ”€ 2.2.1 å€™é€‰æ± é¢„ç­›é€‰ (DPR)
  â”‚   â”‚   dpr_scores = dot(passage_embeddings, question_embedding)
  â”‚   â”‚   candidate_passages = argsort(dpr_scores)[:500]
  â”‚   â”‚
  â”‚   â”œâ”€ 2.2.2 å®ä½“æ‰©å±• (å›¾éå†)
  â”‚   â”‚   activated_entities = {seed_entities}
  â”‚   â”‚   for iteration in range(max_iterations):
  â”‚   â”‚       for entity in activated_entities:
  â”‚   â”‚           # è·å–åŒ…å«è¯¥å®ä½“çš„å¥å­
  â”‚   â”‚           sentences = entity_hash_id_to_sentence_hash_ids[entity]
  â”‚   â”‚           
  â”‚   â”‚           # è®¡ç®—å¥å­ä¸é—®é¢˜çš„ç›¸ä¼¼åº¦
  â”‚   â”‚           sentence_embeddings = get_embeddings(sentences)
  â”‚   â”‚           similarities = dot(sentence_embeddings, question_embedding)
  â”‚   â”‚           
  â”‚   â”‚           # Top-Kç›¸ä¼¼å¥å­
  â”‚   â”‚           top_sentences = argsort(similarities)[:5]
  â”‚   â”‚           
  â”‚   â”‚           # ä»å¥å­ä¸­æå–æ–°å®ä½“
  â”‚   â”‚           for sent in top_sentences:
  â”‚   â”‚               new_entities = sentence_hash_id_to_entity_hash_ids[sent]
  â”‚   â”‚               activated_entities.update(new_entities)
  â”‚   â”‚               entity_weights[new_entities] += scores
  â”‚   â”‚
  â”‚   â”œâ”€ 2.2.3 Passageæƒé‡è®¡ç®—
  â”‚   â”‚   passage_weights = zeros(n_nodes)
  â”‚   â”‚   dpr_scores_normalized = min_max_normalize(dpr_scores)
  â”‚   â”‚   
  â”‚   â”‚   for passage_idx in candidate_passages:
  â”‚   â”‚       passage_hash_id = passage_hash_ids[passage_idx]
  â”‚   â”‚       passage_text = hash_id_to_text[passage_hash_id]
  â”‚   â”‚       
  â”‚   â”‚       # å®ä½“åŒ¹é…åŠ æˆ
  â”‚   â”‚       entity_bonus = 0
  â”‚   â”‚       for entity_id, (_, entity_score, tier) in activated_entities.items():
  â”‚   â”‚           entity_text = hash_id_to_text[entity_id]
  â”‚   â”‚           count = passage_text.count(entity_text)
  â”‚   â”‚           if count > 0:
  â”‚   â”‚               entity_bonus += entity_score * log(1 + count) / tier
  â”‚   â”‚       
  â”‚   â”‚       # ç»„åˆåˆ†æ•°
  â”‚   â”‚       passage_weights[passage_idx] = (
  â”‚   â”‚           passage_ratio * dpr_scores_normalized[passage_idx] + 
  â”‚   â”‚           log(1 + entity_bonus)
  â”‚   â”‚       )
  â”‚   â”‚
  â”‚   â””â”€ 2.2.4 Personalized PageRank (PPR)
  â”‚       node_weights = entity_weights + passage_weights
  â”‚       pagerank_scores = graph.personalized_pagerank(
  â”‚           reset=node_weights,  # é‡å¯åˆ†å¸ƒ
  â”‚           damping=0.85,
  â”‚           weights='weight'
  â”‚       )
  â”‚       # ä»å›¾ä¸­ä¼ æ’­é‡è¦æ€§,å¹³è¡¡å±€éƒ¨(å®ä½“)å’Œå…¨å±€(ç»“æ„)ä¿¡æ¯
  â”‚
  â””â”€ 2.3 ğŸ”¥ è¶…å›¾å¢å¼º (boost_passages_with_entities)
      # === è¾“å…¥ ===
      # 1. å€™é€‰passages (æ¥è‡ªPPRï¼Œå·²æ’åºä½†æœªæˆªæ–­)
      # 2. expanded_entities (æ¥è‡ªè¶…å›¾ï¼Œ~150ä¸ªå®ä½“)
      
      boosted_scores = []
      for passage_hash_id, base_score in zip(passage_hash_ids, passage_scores):
          passage_text = hash_id_to_text[passage_hash_id]
          
          # æ£€æŸ¥æ‰©å±•å®ä½“åŒ¹é…æ•°
          entity_matches = 0
          for entity_id in expanded_entities:  # æ¥è‡ªè¶…å›¾
              entity_text = hypergraph_store.get_entity_text(entity_id)
              if entity_text.lower() in passage_text.lower():
                  entity_matches += 1
          
          # åº”ç”¨å¢å¼ºç³»æ•° (åŒ…å«è¶Šå¤šæ‰©å±•å®ä½“ï¼Œboostè¶Šé«˜)
          if entity_matches > 0:
              boost = 1 + (1.2 - 1) * min(entity_matches, 3) / 3
              base_score *= boost
          
          boosted_scores.append(base_score)
      
      # é‡æ–°æ’åºæ‰€æœ‰passages
      sorted_passages = argsort(boosted_scores)[::-1]
      
      # === è¾“å‡º ===
      # é‡æ’åºåçš„passages (å…¨éƒ¨ï¼Œå°šæœªæˆªæ–­)
  â†“
[Phase 2.5] ğŸ¯ æœ€ç»ˆTop-Kç­›é€‰
  # ä»é‡æ’åºåçš„passagesä¸­å–Top-K
  final_passage_hash_ids = sorted_passage_hash_ids[:5]  # retrieval_top_k=5
  final_passages = [hash_id_to_text[pid] for pid in final_passage_hash_ids]
  
  # === å…³é”®ç‚¹ ===
  # æ‰©å±•å®ä½“ä¸æ˜¯ç›´æ¥ç»™LLMï¼Œè€Œæ˜¯ç”¨äºé‡æ’åºï¼
  # åªæœ‰é‡æ’åºåTop-Kçš„passagesä¼šè¿›å…¥prompt
  â†“
[Phase 3] LLMç”Ÿæˆç­”æ¡ˆ
  â”œâ”€ 3.1 æ„å»ºè¶…è¾¹ä¸Šä¸‹æ–‡ (å¯é€‰)
  â”‚   if top_hyperedges:
  â”‚       context = "[Medical Knowledge Facts]\n"
  â”‚       for i, he_text in enumerate(top_hyperedges[:5]):
  â”‚           context += f"{i+1}. {he_text}\n"
  â”‚       # å°†è¶…è¾¹æ–‡æœ¬(å…³é”®å¥å­)å‰ç½®åˆ°ä¸Šä¸‹æ–‡
  â”‚
  â”œâ”€ 3.2 æ„å»ºPrompt
  â”‚   prompt = f"""Context:
  â”‚   {hyperedge_context}
  â”‚   
  â”‚   {passage_1}
  â”‚   
  â”‚   {passage_2}
  â”‚   ...
  â”‚   
  â”‚   Question: {question}
  â”‚   YOUR RESPONSE MUST BE EXACTLY ONE LETTER: A, B, C, or D"""
  â”‚
  â””â”€ 3.3 LLMæ¨ç†
      response = llm.infer(prompt)
      answer = parse_answer(response)  # æå–A/B/C/D
  â†“
è¾“å‡º: answer
```

### å…³é”®ç®—æ³•è¯¦è§£

#### 1. è¶…å›¾æ£€ç´¢ (Hypergraph Retrieval)
```python
def hypergraph_retrieve(self, question_embedding, seed_entity_hash_ids):
    """è¶…å›¾æ£€ç´¢è¿”å›: ç›¸å…³è¶…è¾¹ã€æ‰©å±•å®ä½“"""
    
    # 1. è¯­ä¹‰åŒ¹é…: é—®é¢˜ vs è¶…è¾¹
    hyperedge_scores = np.dot(
        self.hyperedge_embeddings,      # (n_hyperedges, 768)
        question_embedding.reshape(-1,1) # (768, 1)
    ).flatten()  # (n_hyperedges,)
    
    # 2. åº”ç”¨è¶…è¾¹ç½®ä¿¡åº¦æƒé‡
    for idx, he_id in enumerate(self.hyperedge_hash_ids):
        conf_score = self.hypergraph_store.get_hyperedge_score(he_id)
        # conf_scoreæ¥è‡ªåŒ»å­¦æ¨¡å¼å¢å¼º (1.0-1.5)
        hyperedge_scores[idx] *= conf_score
    
    # 3. Top-Kç­›é€‰
    sorted_indices = np.argsort(hyperedge_scores)[::-1]
    top_hyperedges = []
    for idx in sorted_indices[:30]:  # top_k=30
        if hyperedge_scores[idx] < 0.3:  # threshold
            break
        he_id = self.hyperedge_hash_ids[idx]
        he_text = self.hypergraph_store.get_hyperedge_text(he_id)
        top_hyperedges.append((he_id, he_text, hyperedge_scores[idx]))
    
    # 4. åŒå‘å®ä½“æ‰©å±•
    expanded_entities = set()
    
    # æ–¹å‘A: ä»æ£€ç´¢åˆ°çš„è¶…è¾¹æ‰©å±•
    for he_id, _, _ in top_hyperedges:
        entities = self.hypergraph_store.get_entities_by_hyperedge(he_id)
        expanded_entities.update(entities)
    
    # æ–¹å‘B: ä»ç§å­å®ä½“æ‰©å±• (å¦‚æœæœ‰)
    if seed_entity_hash_ids:
        for entity_id in seed_entity_hash_ids:
            # è·å–åŒ…å«è¯¥å®ä½“çš„æ‰€æœ‰è¶…è¾¹
            related_hyperedges = self.hypergraph_store.get_hyperedges_by_entity(entity_id)
            for he_id in related_hyperedges:
                entities = self.hypergraph_store.get_entities_by_hyperedge(he_id)
                expanded_entities.update(entities)
    
    return (
        [text for _, text, _ in top_hyperedges],  # è¶…è¾¹æ–‡æœ¬
        [score for _, _, score in top_hyperedges], # è¶…è¾¹åˆ†æ•°
        expanded_entities  # æ‰©å±•å®ä½“é›†åˆ
    )
```

**ä¸ºä»€ä¹ˆè¶…å›¾æœ‰æ•ˆ?**
- **æ•æ‰nå…ƒå…³ç³»**: ä¼ ç»ŸäºŒå…ƒè¾¹åªèƒ½è¡¨ç¤ºå®ä½“å¯¹,è¶…è¾¹å¯ä»¥è¡¨ç¤º"ç—‡çŠ¶A + ç—‡çŠ¶B + ç–¾ç—…C"çš„ä¸‰å…ƒå…³ç³»
- **å¥å­çº§è¯­å¢ƒ**: è¶…è¾¹ä¿ç•™åŸå¥å­æ–‡æœ¬,æä¾›å®Œæ•´è¯­ä¹‰ä¸Šä¸‹æ–‡
- **åŒ»å­¦çŸ¥è¯†å¢å¼º**: é€šè¿‡æ¨¡å¼è¯†åˆ«(å¦‚"ç–¾ç—…-è¯ç‰©"),æå‡ä¸´åºŠç›¸å…³è¶…è¾¹çš„é‡è¦æ€§
- **åŒå‘æ‰©å±•**: æ—¢å¯ä»¥ä»é—®é¢˜æ‰¾è¶…è¾¹,ä¹Ÿå¯ä»¥ä»å®ä½“æ‰¾è¶…è¾¹,å¢åŠ å¬å›

#### 2. æ··åˆæ£€ç´¢èåˆ
```python
def hybrid_retrieve(self, question, question_embedding, seed_entity_data):
    """LinearRAGå›¾æ£€ç´¢ + è¶…å›¾å¢å¼º"""
    seed_entity_indices, seed_entities, seed_entity_hash_ids, seed_entity_scores = seed_entity_data
    
    # Part 1: LinearRAGå›¾æ£€ç´¢ (PPR)
    if len(seed_entities) > 0:
        passage_hash_ids, passage_scores = self.graph_search_with_seed_entities(
            question_embedding, seed_entity_indices, seed_entities,
            seed_entity_hash_ids, seed_entity_scores
        )
    else:
        # æ— å®ä½“æ—¶å›é€€åˆ°å¯†é›†æ£€ç´¢
        sorted_indices, sorted_scores = self.dense_passage_retrieval(question_embedding)
        passage_hash_ids = [self.passage_embedding_store.hash_ids[idx] for idx in sorted_indices[:10]]
        passage_scores = sorted_scores[:10]
    
    # Part 2: è¶…å›¾æ£€ç´¢
    hyperedge_context = ""
    if self.use_hypergraph and self.hyperedge_embeddings is not None:
        hyperedge_texts, hyperedge_scores, expanded_entities = self.hypergraph_retrieve(
            question_embedding, seed_entity_hash_ids
        )
        
        # Part 3: ğŸ”¥ ç”¨æ‰©å±•å®ä½“å¢å¼ºpassageæ’åº
        if expanded_entities:
            passage_hash_ids, passage_scores = self._boost_passages_with_entities(
                passage_hash_ids, passage_scores, expanded_entities
            )
        
        # Part 4: æ ¼å¼åŒ–è¶…è¾¹ä¸Šä¸‹æ–‡ (ç”¨äºLLMç”Ÿæˆ)
        if hyperedge_texts:
            hyperedge_context = self._format_hyperedge_context(
                hyperedge_texts, hyperedge_scores
            )
    
    return passage_hash_ids, passage_scores, hyperedge_context
```

---

## å…·ä½“ç¤ºä¾‹è¯¦è§£

### ç¤ºä¾‹åœºæ™¯
- **Chunk**: "Metformin is the first-line pharmacological treatment for type 2 diabetes mellitus. It reduces hepatic glucose production and improves insulin sensitivity."
- **Query**: "What is the first-line treatment for type 2 diabetes?"

### Step-by-Stepå·¥ä½œæµ

#### 1. ç´¢å¼•é˜¶æ®µ

##### 1.1 Chunkæ’å…¥
```
passage_text = "Metformin is the first-line pharmacological treatment..."
passage_hash_id = md5(passage_text)[:16]  # ä¾‹: "a3f5b2c8d1e9..."
passage_embedding = SentenceTransformer.encode(passage_text)  # (768,)
```

##### 1.2 NERæå–
```python
# BC5CDR NER
entities = ["metformin", "type 2 diabetes mellitus", "glucose", "insulin"]

# HuggingFace NER (è¡¥å……)
additional_entities = ["hepatic glucose production", "insulin sensitivity"]

# åˆå¹¶
all_entities = ["metformin", "type 2 diabetes mellitus", "glucose", 
                "insulin", "hepatic glucose production", "insulin sensitivity"]

# å¥å­çº§æå–
sentence_1 = "Metformin is the first-line pharmacological treatment for type 2 diabetes mellitus."
sentence_1_entities = {"metformin", "type 2 diabetes mellitus"}

sentence_2 = "It reduces hepatic glucose production and improves insulin sensitivity."
sentence_2_entities = {"glucose", "insulin", "hepatic glucose production", "insulin sensitivity"}
```

å­˜å‚¨åˆ°:
```python
passage_hash_id_to_entities[passage_hash_id] = {
    "metformin", "type 2 diabetes mellitus", "glucose", "insulin", ...
}

sentence_to_entities = {
    "Metformin is the first-line...": {"metformin", "type 2 diabetes mellitus"},
    "It reduces hepatic glucose...": {"glucose", "insulin", ...}
}
```

##### 1.3 åŸºç¡€å›¾æ„å»º
```
èŠ‚ç‚¹:
  - passage_node: (passage_hash_id, content="Metformin is the first-line...")
  - entity_nodes: (entity_hash_ids, content=["metformin", "type 2 diabetes mellitus", ...])
  - sentence_nodes: (sentence_hash_ids, content=[å¥å­1, å¥å­2])

è¾¹:
  - passage â†’ metformin: weight = 1/6 (å‡ºç°1æ¬¡,å…±6ä¸ªå®ä½“)
  - passage â†’ type 2 diabetes mellitus: weight = 1/6
  - entity â†’ sentence: å…±ç°å…³ç³»
```

##### 1.4 è¶…å›¾æ„å»º ğŸ”¥
```python
# å¥å­1: åŒ…å«2ä¸ªå®ä½“ â†’ æ„å»ºè¶…è¾¹
hyperedge_1 = Hyperedge(
    text="Metformin is the first-line pharmacological treatment for type 2 diabetes mellitus.",
    entities=["metformin", "type 2 diabetes mellitus"],
    score=2/4,  # 2ä¸ªå®ä½“ / max_entity_count=4
    hash_id="he_abc123"
)

# åŒ»å­¦æ¨¡å¼å¢å¼º
entity_types = {"metformin": "CHEMICAL", "type 2 diabetes mellitus": "DISEASE"}
# æ£€æµ‹åˆ°æ¨¡å¼: {CHEMICAL, DISEASE} â†’ ç–¾ç—…-è¯ç‰©å…³ç³»
hyperedge_1.score *= 1.3  # å¢å¼ºç³»æ•°
# æœ€ç»ˆscore: (2/4) * 1.3 = 0.65

# å¥å­2: åŒ…å«4ä¸ªå®ä½“ â†’ æ„å»ºè¶…è¾¹
hyperedge_2 = Hyperedge(
    text="It reduces hepatic glucose production and improves insulin sensitivity.",
    entities=["glucose", "insulin", "hepatic glucose production", "insulin sensitivity"],
    score=4/4 * 1.0,  # æ— ç‰¹æ®ŠåŒ»å­¦æ¨¡å¼
    hash_id="he_def456"
)

# å­˜å‚¨åˆ°HypergraphStore (äºŒéƒ¨å›¾)
# Entity nodes: metformin, type 2 diabetes mellitus, glucose, insulin, ...
# Hyperedge nodes: he_abc123, he_def456
# Edges:
#   - (metformin, he_abc123)
#   - (type 2 diabetes mellitus, he_abc123)
#   - (glucose, he_def456)
#   - (insulin, he_def456)
#   - ...
```

æ˜ å°„å…³ç³»:
```python
passage_to_hyperedge_ids[passage_hash_id] = ["he_abc123", "he_def456"]

entity_to_hyperedges = {
    "metformin": {"he_abc123"},
    "type 2 diabetes mellitus": {"he_abc123"},
    "glucose": {"he_def456"},
    "insulin": {"he_def456"},
    ...
}

hyperedge_to_entities = {
    "he_abc123": {"metformin", "type 2 diabetes mellitus"},
    "he_def456": {"glucose", "insulin", ...}
}
```

##### 1.5 è¶…è¾¹Embedding
```python
hyperedge_embeddings = SentenceTransformer.encode([
    "Metformin is the first-line pharmacological treatment for type 2 diabetes mellitus.",
    "It reduces hepatic glucose production and improves insulin sensitivity."
])
# Shape: (2, 768)
```

---

#### 2. æ£€ç´¢é˜¶æ®µ

##### 2.1 Queryå¤„ç†
```python
question = "What is the first-line treatment for type 2 diabetes?"

# NERæå–
question_entities = ["treatment", "type 2 diabetes"]  # BC5CDR + HF

# å®ä½“åŒ¹é…
question_entity_embeddings = encode(["treatment", "type 2 diabetes"])
# Shape: (2, 768)

similarities = dot(entity_embeddings, question_entity_embeddings.T)
# entity_embeddings: (n_entities, 768)
# similarities: (n_entities, 2)

# ä¸ºæ¯ä¸ªé—®é¢˜å®ä½“æ‰¾æœ€ç›¸ä¼¼çš„åº“å†…å®ä½“
for q_idx in range(2):
    best_match_idx = argmax(similarities[:, q_idx])
    best_match_text = entity_texts[best_match_idx]
    best_match_score = similarities[best_match_idx, q_idx]

# ç»“æœ:
seed_entities = [
    ("drug therapy", 0.82, "treatmentçš„åŒ¹é…"),  # å‡è®¾
    ("type 2 diabetes mellitus", 0.96, "ç²¾ç¡®åŒ¹é…")
]

# Question embedding
question_embedding = encode(question)  # (768,)
```

##### 2.2 è¶…å›¾æ£€ç´¢ ğŸ”¥
```python
# Step 1: è¶…è¾¹è¯­ä¹‰åŒ¹é…
hyperedge_scores = dot(hyperedge_embeddings, question_embedding)
# hyperedge_embeddings: (2, 768)
# question_embedding: (768,)
# ç»“æœ: [0.78, 0.45]  (hyperedge_1ç›¸å…³åº¦é«˜)

# Step 2: åº”ç”¨ç½®ä¿¡åº¦æƒé‡
hyperedge_scores[0] *= 0.65  # hyperedge_1çš„score
hyperedge_scores[1] *= 1.0   # hyperedge_2çš„score
# ç»“æœ: [0.507, 0.45]

# Step 3: Top-Kç­›é€‰
sorted_indices = argsort([0.507, 0.45])[::-1]  # [0, 1]
top_hyperedges = [
    ("he_abc123", "Metformin is the first-line...", 0.507),
    ("he_def456", "It reduces hepatic glucose...", 0.45)
]

# Step 4: åŒå‘å®ä½“æ‰©å±•
expanded_entities = set()

# æ–¹å‘A: ä»topè¶…è¾¹æ‰©å±•
# he_abc123 â†’ {"metformin", "type 2 diabetes mellitus"}
expanded_entities.update(["metformin", "type 2 diabetes mellitus"])
# he_def456 â†’ {"glucose", "insulin", ...}
expanded_entities.update(["glucose", "insulin", "hepatic glucose production", "insulin sensitivity"])

# æ–¹å‘B: ä»ç§å­å®ä½“æ‰©å±•
# seed: "type 2 diabetes mellitus"
related_hyperedges = entity_to_hyperedges["type 2 diabetes mellitus"]
# â†’ {"he_abc123"} (å·²ç»åœ¨topä¸­)

# seed: "drug therapy" (å‡è®¾åº“ä¸­è¿˜å…³è”å…¶ä»–è¶…è¾¹)
# å‡è®¾å…³è”åˆ°å…¶ä»–ç³–å°¿ç—…è¯ç‰©çš„è¶…è¾¹,æ‰©å±•æ›´å¤šå®ä½“...

# æœ€ç»ˆæ‰©å±•å®ä½“: 
expanded_entities = {
    "metformin", "type 2 diabetes mellitus", "glucose", "insulin",
    "hepatic glucose production", "insulin sensitivity",
    # + å…¶ä»–ä»ç§å­å®ä½“æ‰©å±•çš„ç›¸å…³å®ä½“
}
```

##### 2.3 LinearRAGå›¾æ£€ç´¢
```python
# Step 1: DPRå€™é€‰æ± 
dpr_scores = dot(passage_embeddings, question_embedding)
# å‡è®¾æˆ‘ä»¬çš„passageæ’åœ¨ç¬¬10ä½: dpr_scores[10] = 0.68
candidate_passages = argsort(dpr_scores)[:500]  # Top-500
# passage_hash_idåœ¨å€™é€‰æ± ä¸­

# Step 2: å®ä½“æ‰©å±• (å›¾éå†)
activated_entities = {
    "type 2 diabetes mellitus": (idx1, 0.96, tier=1),  # ç§å­å®ä½“
    "drug therapy": (idx2, 0.82, tier=1)
}

# Iteration 1
for entity_id, (_, score, tier) in activated_entities.items():
    # è·å–åŒ…å«è¯¥å®ä½“çš„å¥å­
    if entity_id == "type 2 diabetes mellitus":
        sentences = [sentence_1_hash_id, ...]  # å¥å­:"Metformin is..."
        
        # è®¡ç®—å¥å­ç›¸ä¼¼åº¦
        sent_embeddings = sentence_embeddings[[sentence_1_idx, ...]]
        sent_similarities = dot(sent_embeddings, question_embedding)
        # [0.82, ...]
        
        # Topå¥å­çš„å®ä½“
        top_sent = sentence_1
        new_entities = sentence_hash_id_to_entity_hash_ids[sentence_1_hash_id]
        # â†’ {"metformin", "type 2 diabetes mellitus"}
        
        # æ›´æ–°æƒé‡
        entity_weights[metformin_idx] += 0.96 * 0.82  # seed_score * sent_similarity
        # æ–°å®ä½“: metformin (tier=2)
        activated_entities["metformin"] = (metformin_idx, 0.96*0.82, 2)

# Iteration 2 (å¦‚æœéœ€è¦)
# ä»metforminç»§ç»­æ‰©å±•...

# Step 3: Passageæƒé‡è®¡ç®—
passage_weights = zeros(n_nodes)

for passage_idx in candidate_passages:
    if passage_hash_id == current_passage_hash_id:
        passage_text = "Metformin is the first-line..."
        
        # DPRåŸºç¡€åˆ†æ•°
        dpr_score_norm = min_max_normalize(0.68)  # å‡è®¾0.75
        
        # å®ä½“åŒ¹é…åŠ æˆ
        entity_bonus = 0
        
        # "type 2 diabetes mellitus"å‡ºç°1æ¬¡
        entity_bonus += 0.96 * log(1 + 1) / 1  # score * log(1+count) / tier
        # = 0.96 * 0.693 = 0.665
        
        # "metformin"å‡ºç°1æ¬¡
        entity_bonus += 0.787 * log(1 + 1) / 2  # tier=2
        # = 0.787 * 0.693 / 2 = 0.273
        
        # "drug therapy"ä¸åœ¨æ–‡æœ¬ä¸­,è·³è¿‡
        
        # æ€»åŠ æˆ: 0.665 + 0.273 = 0.938
        
        # æœ€ç»ˆæƒé‡
        passage_weights[passage_node_idx] = (
            0.7 * 0.75 +          # passage_ratio * dpr_score
            log(1 + 0.938)        # log(1 + entity_bonus)
        )
        # = 0.525 + 0.661 = 1.186

# Step 4: PPR
node_weights = entity_weights + passage_weights
# node_weights[passage_node_idx] = 1.186
# node_weights[metformin_idx] = 0.787
# node_weights[type2dm_idx] = 0.96
# ...

pagerank_scores = graph.personalized_pagerank(
    reset=node_weights,
    damping=0.85,
    weights='weight'
)
# PPRä»é«˜æƒé‡èŠ‚ç‚¹å¼€å§‹éšæœºæ¸¸èµ°,æƒé‡æ²¿è¾¹ä¼ æ’­
# ç»“æœ: passage_nodeè·å¾—é«˜PageRankåˆ†æ•° (å› ä¸ºç›´æ¥è¿æ¥é«˜æƒé‡å®ä½“)

# æå–passageæ’åº
doc_scores = pagerank_scores[passage_node_indices]
sorted_passages = argsort(doc_scores)[::-1]
# æˆ‘ä»¬çš„passageå¾ˆå¯èƒ½æ’åœ¨å‰åˆ—
```

##### 2.4 è¶…å›¾å¢å¼º ğŸ”¥

**å…³é”®é—®é¢˜**: æ‰©å±•å®ä½“æœ‰ä¸Šç™¾ä¸ªï¼Œä½†æœ€ç»ˆåªç»™LLM Top-K(å¦‚5ä¸ª)æ–‡æ¡£ï¼Œå¦‚ä½•ç­›é€‰ï¼Ÿ

**ç­”æ¡ˆ**: æ‰©å±•å®ä½“ä¸æ˜¯ç›´æ¥ç»™LLMï¼Œè€Œæ˜¯ç”¨æ¥**é‡æ–°æ’åºæ‰€æœ‰å€™é€‰passages**ï¼

```python
# === æ­¥éª¤1: PPRå›¾æ£€ç´¢è¿”å›æ’åºçš„æ‰€æœ‰passages ===
# (æ³¨æ„: è¿™é‡Œè¿”å›çš„æ˜¯å…¨éƒ¨æ’åºç»“æœï¼Œä¸æ˜¯Top-K)
passage_hash_ids, passage_scores = graph_search_with_seed_entities(...)
# ä¾‹å¦‚: 20000ä¸ªpassagesçš„å®Œæ•´æ’åº
# [passage_1, passage_2, ..., passage_20000]
# [score_1,   score_2,   ..., score_20000]

# === æ­¥éª¤2: è¶…å›¾æ£€ç´¢å¾—åˆ°æ‰©å±•å®ä½“ ===
expanded_entities = hypergraph_retrieve(...)
# ä¾‹å¦‚: 150ä¸ªæ‰©å±•å®ä½“
# {"metformin", "type 2 diabetes", "glucose", "insulin", ...}

# === æ­¥éª¤3: ğŸ”¥ ç”¨æ‰©å±•å®ä½“boostæ‰€æœ‰passagesçš„åˆ†æ•° ===
boosted_scores = []
for passage_hash_id, base_score in zip(passage_hash_ids, passage_scores):
    passage_text = hash_id_to_text[passage_hash_id]
    
    # ç»Ÿè®¡è¯¥passageåŒ…å«å¤šå°‘ä¸ªæ‰©å±•å®ä½“
    entity_matches = 0
    for entity_id in expanded_entities:
        entity_text = hypergraph_store.get_entity_text(entity_id)
        if entity_text and entity_text.lower() in passage_text.lower():
            entity_matches += 1
    
    # åº”ç”¨boost (åŒ…å«è¶Šå¤šæ‰©å±•å®ä½“ï¼Œboostè¶Šå¤§)
    if entity_matches > 0:
        boost = 1 + (1.2 - 1) * min(entity_matches, 3) / 3
        # æœ€å¤šbooståˆ°1.2å€ (å½“åŒ¹é…3ä¸ªæˆ–ä»¥ä¸Šå®ä½“æ—¶)
        boosted_score = base_score * boost
    else:
        boosted_score = base_score
    
    boosted_scores.append(boosted_score)

# === æ­¥éª¤4: é‡æ–°æ’åºæ‰€æœ‰passages ===
sorted_pairs = sorted(
    zip(passage_hash_ids, boosted_scores),
    key=lambda x: x[1],
    reverse=True
)
reranked_passage_hash_ids = [p[0] for p in sorted_pairs]
reranked_passage_scores = [p[1] for p in sorted_pairs]

# === æ­¥éª¤5: ğŸ¯ æœ€ç»ˆTop-Kç­›é€‰ ===
final_passage_hash_ids = reranked_passage_hash_ids[:5]  # retrieval_top_k=5
final_passage_scores = reranked_passage_scores[:5]
final_passages = [hash_id_to_text[pid] for pid in final_passage_hash_ids]

# ç»“æœ: åªæœ‰5ä¸ªpassagesè¿›å…¥prompt
# è¿™5ä¸ªæ˜¯ç»è¿‡è¶…å›¾å®ä½“æ‰©å±•å¢å¼ºåæ’åæœ€é«˜çš„
```

**ç¤ºä¾‹è¯´æ˜**:

å‡è®¾æˆ‘ä»¬çš„ç›®æ ‡passageåˆå§‹æ’åç¬¬8:
```
åˆå§‹æ’å (PPR):
1. passage_A (score=1.85, åŒ…å«0ä¸ªæ‰©å±•å®ä½“)
2. passage_B (score=1.72, åŒ…å«1ä¸ªæ‰©å±•å®ä½“)
...
8. passage_target (score=1.45, åŒ…å«3ä¸ªæ‰©å±•å®ä½“: metformin, type 2 diabetes, insulin)
...

åº”ç”¨è¶…å›¾boostå:
- passage_A: 1.85 * 1.0 = 1.85 (æ— boost)
- passage_B: 1.72 * 1.067 = 1.835 (boost=1+(1.2-1)*1/3)
- passage_target: 1.45 * 1.2 = 1.74 (boost=1+(1.2-1)*3/3)

é‡æ–°æ’åå:
1. passage_A (score=1.85)
2. passage_B (score=1.835)
3. passage_target (score=1.74) â† ä»ç¬¬8å‡è‡³ç¬¬3ï¼
...

æœ€ç»ˆTop-5:
passage_targetæˆåŠŸè¿›å…¥Top-5ï¼Œä¼šè¢«é€ç»™LLM
```

**æ ¸å¿ƒæœºåˆ¶**:
- æ‰©å±•å®ä½“ = **ä¿¡å·**: æ ‡è®°å“ªäº›passageæ›´ç›¸å…³
- Boost = **é‡æ’åº**: æå‡åŒ…å«æ‰©å±•å®ä½“çš„passages
- Top-K = **æˆªæ–­**: æœ€ç»ˆåªå–booståæ’åæœ€é«˜çš„Kä¸ª

##### 2.5 æ„å»ºLLMä¸Šä¸‹æ–‡
```python
# è¶…è¾¹ä¸Šä¸‹æ–‡
hyperedge_context = """[Medical Knowledge Facts]
1. Metformin is the first-line pharmacological treatment for type 2 diabetes mellitus.
2. It reduces hepatic glucose production and improves insulin sensitivity.
"""

# å®Œæ•´prompt
prompt = f"""Context:
{hyperedge_context}

Passage 1: Metformin is the first-line pharmacological treatment for type 2 diabetes mellitus. It reduces hepatic glucose production and improves insulin sensitivity.

Passage 2: ... (å…¶ä»–æ£€ç´¢åˆ°çš„passage)

...

Question: What is the first-line treatment for type 2 diabetes?
Options:
A. Insulin
B. Metformin
C. Sulfonylureas
D. DPP-4 inhibitors

YOUR RESPONSE MUST BE EXACTLY ONE LETTER: A, B, C, or D
"""

# LLMæ¨ç†
response = llm.infer(prompt)
# è¾“å‡º: "B"

# ç­”æ¡ˆè§£æ
answer = parse_answer(response)  # "B"
```

---

### å…³é”®æœºåˆ¶æ€»ç»“

#### 1. è¶…å›¾å¦‚ä½•å¸®åŠ©æ£€ç´¢?
```
é—®é¢˜: "What is the first-line treatment for type 2 diabetes?"

ä¼ ç»ŸDPR:
  question_embedding â†’ passage_embeddings
  â†“
  è¯­ä¹‰åŒ¹é…å¯èƒ½é”™è¿‡å…³é”®ä¿¡æ¯ (å¦‚"first-line"è¿™ä¸ªé‡è¦é™å®š)

LinearRAG (æ— è¶…å›¾):
  question â†’ å®ä½“["treatment", "type 2 diabetes"] â†’ å›¾éå† â†’ passages
  â†“
  é€šè¿‡å®ä½“è¿æ¥æ‰¾åˆ°ç›¸å…³passages,ä½†å®ä½“æ‰©å±•å¯èƒ½ä¸å……åˆ†

LinearRAG + Hypergraph:
  question â†’ å®ä½“ + è¶…è¾¹è¯­ä¹‰åŒ¹é…
  â†“
  è¶…è¾¹ = å¥å­çº§å…³ç³» ("Metformin + type 2 diabetes + first-line treatment")
  â†“
  åŒå‘æ‰©å±•: 
    - è¶…è¾¹â†’å®ä½“: å‘ç°"metformin"(å¯èƒ½ä¸åœ¨é—®é¢˜ä¸­)
    - å®ä½“â†’è¶…è¾¹: å‘ç°ç›¸å…³ä¸´åºŠçŸ¥è¯†
  â†“
  æ‰©å±•å®ä½“å¢å¼ºpassageæ’åº
  â†“
  Topè¶…è¾¹å¥å­ä½œä¸ºçŸ¥è¯†äº‹å®æç¤ºLLM
```

**ä¼˜åŠ¿**:
1. **è¯­ä¹‰è¡¥å…¨**: é—®é¢˜åªæ"treatment",è¶…å›¾å¸®åŠ©æ‰¾åˆ°å…·ä½“è¯ç‰©"metformin"
2. **å…³ç³»ä¿ç•™**: è¶…è¾¹ä¿ç•™å®Œæ•´å¥å­è¯­å¢ƒ,ä¸ä¸¢å¤±"first-line"ç­‰å…³é”®é™å®šè¯
3. **çŸ¥è¯†å¢å¼º**: åŒ»å­¦æ¨¡å¼è¯†åˆ«æå‡ä¸´åºŠç›¸å…³è¶…è¾¹,ä¼˜å…ˆå¬å›æ²»ç–—å»ºè®®ç±»çŸ¥è¯†
4. **åŒå‘èåˆ**: åŒæ—¶åˆ©ç”¨é—®é¢˜è¯­ä¹‰(è¶…è¾¹åŒ¹é…)å’Œå®ä½“ç»“æ„(å›¾éå†)

#### 2. ä¸ºä»€ä¹ˆéœ€è¦å›¾+è¶…å›¾æ··åˆ?
```
å›¾ (LinearRAG):
  ä¼˜åŠ¿: ç»“æ„åŒ–éå†,åˆ©ç”¨å®ä½“å…±ç°å’Œæ–‡æ¡£ç»„ç»‡
  å±€é™: äºŒå…ƒè¾¹æ— æ³•è¡¨è¾¾å¤šå®ä½“å¤æ‚å…³ç³»

è¶…å›¾ (Hypergraph):
  ä¼˜åŠ¿: nå…ƒå…³ç³»,å¥å­çº§è¯­å¢ƒ,åŒ»å­¦æ¨¡å¼è¯†åˆ«
  å±€é™: å­¤ç«‹çš„è¶…è¾¹ç¼ºä¹å…¨å±€ç»“æ„ä¿¡æ¯

æ··åˆ (HyperLinearRAG):
  å›¾æä¾›ç»“æ„åŒ–æ£€ç´¢è·¯å¾„
  â†“
  è¶…å›¾æ‰©å±•å®ä½“å¹¶æä¾›è¯­ä¹‰å¢å¼º
  â†“
  ç›¸äº’è¡¥å……,æå‡å¬å›å’Œå‡†ç¡®ç‡
```

#### 3. è¶…è¾¹ç½®ä¿¡åº¦åˆ†æ•°çš„ä½œç”¨
```python
# æ„å»ºæ—¶: åŸºäºå®ä½“æ•°é‡å’ŒåŒ»å­¦æ¨¡å¼
base_score = len(entities) / max_entity_count  # 0.0-1.0

# åŒ»å­¦æ¨¡å¼å¢å¼º
if {DISEASE, CHEMICAL} in entity_types:
    score *= 1.3  # ç–¾ç—…-è¯ç‰©: ä¸´åºŠé«˜ç›¸å…³

# æ£€ç´¢æ—¶: è°ƒæ•´è¶…è¾¹é‡è¦æ€§
hyperedge_score = semantic_similarity * confidence_score
# æ—¢è€ƒè™‘è¯­ä¹‰åŒ¹é…,ä¹Ÿè€ƒè™‘åŒ»å­¦é¢†åŸŸä»·å€¼
```

è¿™ç¡®ä¿äº†ä¸´åºŠç›¸å…³çš„è¶…è¾¹(å¦‚"ç—‡çŠ¶-è¯Šæ–­"ã€"ç–¾ç—…-æ²»ç–—")åœ¨æ£€ç´¢æ—¶è·å¾—æ›´é«˜æƒé‡ã€‚

---

## æ€§èƒ½æŒ‡æ ‡

æ ¹æ®é…ç½®å’Œä»£ç æ³¨é‡Š:

| ç»„ä»¶ | è§„æ¨¡ | è¯´æ˜ |
|------|------|------|
| Passages | 20000 | PubMedæ–‡çŒ®chunks |
| Entities | ~50000 | åŒ»å­¦å®ä½“ (CHEMICAL, DISEASEç­‰) |
| Sentences | ~100000 | åŒ…å«å®ä½“çš„å¥å­ |
| Hyperedges | ~60000 | å¥å­çº§è¶…è¾¹(â‰¥2å®ä½“) |
| Graph nodes | ~170000 | passages + entities + sentences |
| Graph edges | ~500000 | passage-entity + entity-sentence + passage-passage |
| Hypergraph edges | ~120000 | entity-hyperedge (äºŒéƒ¨å›¾) |

æ£€ç´¢æ€§èƒ½:
- **ç´¢å¼•æ—¶é—´**: ~200-300ç§’ (20k passages)
- **å•queryæ£€ç´¢**: ~0.5-1ç§’
  - è¶…å›¾æ£€ç´¢: ~0.1ç§’
  - å›¾éå†(PPR): ~0.3ç§’
  - å¢å¼º+æ’åº: ~0.1ç§’
- **å‡†ç¡®ç‡æå‡**: ç›¸æ¯”çº¯DPRæå‡5-10% (æ ¹æ®MIRAGEåŸºå‡†)

---

## æ€»ç»“

**LinearRAG + Hypergraphçš„æ ¸å¿ƒåˆ›æ–°**:

1. **å¤šå±‚æ¬¡çŸ¥è¯†è¡¨ç¤º**:
   - æ–‡æ¡£å±‚: passage embeddings (DPR)
   - å®ä½“å±‚: entity graph (ç»“æ„åŒ–çŸ¥è¯†)
   - å…³ç³»å±‚: hyperedges (å¥å­çº§nå…ƒå…³ç³»)

2. **æ··åˆæ£€ç´¢ç­–ç•¥**:
   - å¯†é›†æ£€ç´¢ (DPR): è¯­ä¹‰ç›¸ä¼¼åº¦
   - å›¾éå† (PPR): å®ä½“è¿æ¥å’Œç»“æ„
   - è¶…å›¾åŒ¹é…: å¤šå®ä½“å…³ç³»å’ŒåŒ»å­¦æ¨¡å¼

3. **åŒå‘èåˆæœºåˆ¶**:
   - Top-down: é—®é¢˜â†’è¶…è¾¹â†’å®ä½“â†’passages
   - Bottom-up: é—®é¢˜â†’å®ä½“â†’å›¾éå†â†’passages
   - è¶…å›¾æ‰©å±•çš„å®ä½“å¢å¼ºæœ€ç»ˆæ’åº

4. **é¢†åŸŸä¼˜åŒ–**:
   - åŒ»å­¦NER (BC5CDR + HuggingFace)
   - åŒ»å­¦å…³ç³»æ¨¡å¼è¯†åˆ« (ç–¾ç—…-è¯ç‰©ã€ç—‡çŠ¶-è¯Šæ–­ç­‰)
   - ä¸´åºŠç›¸å…³æ€§re-ranking

5. **ğŸ”¥ æ‰©å±•å®ä½“çš„ä½œç”¨æœºåˆ¶**:
   - **ä¸æ˜¯ç›´æ¥è¾“å…¥**: æ‰©å±•å®ä½“(~150ä¸ª)ä¸ä¼šç›´æ¥ç»™LLM
   - **ç”¨äºé‡æ’åº**: ä½œä¸ºä¿¡å·booståŒ…å«è¿™äº›å®ä½“çš„passages
   - **æœ€ç»ˆæˆªæ–­**: åªæœ‰é‡æ’åºåTop-K(5ä¸ª)passagesè¿›å…¥prompt
   - **æ•ˆæœ**: è®©åŸæœ¬æ’åè¾ƒä½ä½†åŒ…å«å…³é”®å®ä½“çš„æ–‡æ¡£å¾—ä»¥æµ®ç°

è¿™ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿåœ¨å¤§è§„æ¨¡åŒ»å­¦æ–‡çŒ®ä¸­å‡†ç¡®æ‰¾åˆ°å›ç­”å¤æ‚ä¸´åºŠé—®é¢˜æ‰€éœ€çš„çŸ¥è¯†ç‰‡æ®µã€‚

---

## å®Œæ•´æ•°æ®æµæ€»ç»“

```
è¾“å…¥: Question "What is the first-line treatment for type 2 diabetes?"
  â†“
[NER] â†’ ç§å­å®ä½“: ["treatment", "type 2 diabetes"]
  â†“
[è¶…å›¾æ£€ç´¢] 
  â†’ Top-30è¶…è¾¹ (è¯­ä¹‰åŒ¹é…)
  â†’ æ‰©å±•å®ä½“: ~150ä¸ª ["metformin", "insulin", "glucose", ...]
  â†“
[å›¾æ£€ç´¢PPR]
  â†’ æ’åºæ‰€æœ‰20000ä¸ªpassages (åŸºäºå®ä½“å›¾éå†)
  â†“
[è¶…å›¾å¢å¼º]
  â†’ ç”¨150ä¸ªæ‰©å±•å®ä½“é‡æ’åºæ‰€æœ‰passages
  â†’ åŒ…å«æ›´å¤šæ‰©å±•å®ä½“çš„passageåˆ†æ•°æå‡
  â†“
[Top-Kæˆªæ–­]
  â†’ å–é‡æ’åºåTop-5 passages
  â†“
[LLMç”Ÿæˆ]
  â†’ Prompt = [è¶…è¾¹ä¸Šä¸‹æ–‡(Top-5è¶…è¾¹å¥å­)] + [Top-5 passages] + [Question]
  â†’ ç­”æ¡ˆ: "B. Metformin"
```

**å…³é”®æ´å¯Ÿ**: 
- æ‰©å±•å®ä½“æ˜¯**æ’åºä¿¡å·**ï¼Œä¸æ˜¯**è¾“å…¥å†…å®¹**
- è¶…è¾¹æ–‡æœ¬(Top-5)ä½œä¸º**çŸ¥è¯†æç¤º**è¿›å…¥prompt
- Passages(Top-5)æ˜¯**ä¸»è¦ä¸Šä¸‹æ–‡**
- ä¸‰è€…ååŒï¼Œç¡®ä¿LLMçœ‹åˆ°æœ€ç›¸å…³çš„ä¿¡æ¯

